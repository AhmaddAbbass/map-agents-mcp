# Reflection

Working on this assignment made the relationship between **MCP** and the **OpenAI Agents SDK** feel much more concrete. At the beginning, MCP was just a buzzword about “standardizing tools,” but once I actually wrote the OSM and OSRM servers, it clicked that MCP is really the contract between the outside world and the agent. Each server is just a thin, testable wrapper around a real HTTP API (Nominatim and OSRM), and once it speaks MCP, any compatible agent can plug it in and discover its tools. The OpenAI Agent then becomes a reusable “brain” that reasons over natural language while delegating all map-specific work to these servers.

The debugging process also taught me a lot about practical details. I had to clean up a conflicting `agents` package that pulled in old TensorFlow and Gym, and then re-install the actual `openai-agents` library inside my virtualenv. I also had to respect real-world constraints of the map services: Nominatim requires a custom User-Agent and isn’t meant for heavy bulk usage, and OSRM expects coordinates in `lon,lat` order and returns distances in meters and durations in seconds. Designing small, composable tools—`search_place`, `reverse_geocode`, `search_pois`, `route_between`, `route_summary`, and `distance_matrix`—made it much easier to test each piece with simple scripts and then watch the agent chain them together. Overall, the project turned MCP from an abstract protocol into something very tangible: a clean, modular way to give an agent real geospatial powers without hard-wiring the logic into the model itself.
